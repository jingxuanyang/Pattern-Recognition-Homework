{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd097ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# AdaBoost Algorithm\n",
    "+ Author: Jingxuan Yang\n",
    "+ E-mail: yangjx20@mails.tsinghua.edu.cn\n",
    "+ Page: www.jingxuanyang.com\n",
    "+ Date: 2021-05-21\n",
    "+ Project: Pattern Recognition, homework 12\n",
    "+ Purpose: Implement AdaBoost algorithm on `ada_data.mat` dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "## Utils"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost(X, y, X_test, y_test, maxIter):\n",
    "    '''\n",
    "    adaboost: carry on adaboost on the data for maxIter loops\n",
    "    Input \n",
    "        X       : n * p matirx, training data\n",
    "        y       : (n, ) vector, training label\n",
    "        X_test  : m * p matrix, testing data\n",
    "        y_test  : (m, ) vector, testing label\n",
    "        maxIter : number of loops\n",
    "    Output\n",
    "        e_train : (maxIter, ) vector, errors on training data\n",
    "        e_test  : (maxIter, ) vector, errors on testing data\n",
    "    '''\n",
    "\n",
    "    w = np.ones(y.shape, dtype='float') / y.shape[0]\n",
    "\n",
    "    k = np.zeros(maxIter, dtype='int')\n",
    "    a = np.zeros(maxIter)\n",
    "    d = np.zeros(maxIter)\n",
    "    alpha = np.zeros(maxIter)\n",
    "\n",
    "    e_train = np.zeros(maxIter)\n",
    "    e_test = np.zeros(maxIter)\n",
    "\n",
    "    for i in range(maxIter):\n",
    "        k[i], a[i], d[i] = decision_stump(X, y, w)\n",
    "        \n",
    "        e = decision_stump_error(X, y, k[i], a[i], d[i], w)\n",
    "        print('new decision stump k:%d a:%f, d:%d, e:%f' % (k[i], a[i], d[i],e))\n",
    "        alpha[i] = 1/2 * np.log((1 - e) / e)\n",
    "        # alpha[i] = np.log((1 - e) / e)\n",
    "        w = update_weights(X, y, k[i], a[i], d[i], w, alpha[i])\n",
    "        \n",
    "        e_train[i] = adaboost_error(X, y, k, a, d, alpha)\n",
    "        e_test[i] = adaboost_error(X_test, y_test, k, a, d, alpha)\n",
    "        print('weak learner error rate: %f\\nadaboost error rate: %f\\ntest error rate: %f\\n' % (e, e_train[i], e_test[i]))\n",
    "\n",
    "    return e_train, e_test\n",
    "\n",
    "\n",
    "def decision_stump(X, y, w):\n",
    "    '''\n",
    "    decision_stump returns a rule ...\n",
    "    h(x) = d if x(k) <= a, âˆ’d otherwise,\n",
    "    Input\n",
    "        X : n * p matrix, each row a sample\n",
    "        y : (n, ) vector, each row a label\n",
    "        w : (n, ) vector, each row a weight\n",
    "    Output\n",
    "        k : the optimal dimension\n",
    "        a : the optimal threshold\n",
    "        d : the optimal d, 1 or -1\n",
    "    '''\n",
    "\n",
    "    # total time complexity required to be O(p*n*logn) or less\n",
    "    ### Your Code Here ###\n",
    "    p = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "\n",
    "    k = -1\n",
    "    a = -1\n",
    "    d = 0\n",
    "    max_prune = 0\n",
    "\n",
    "    for i in range(p):\n",
    "        s = np.argsort(X[:,i])\n",
    "        char = X[:,i][s]\n",
    "        w_sort = w[s]\n",
    "        y_sort = y[s]\n",
    "\n",
    "        integral = 0\n",
    "        \n",
    "        for j in range(n):\n",
    "            integral += y_sort[j] * w_sort[j]\n",
    "            if abs(integral) > max_prune:\n",
    "                max_prune = abs(integral)\n",
    "                k = i\n",
    "                if j == n-1:\n",
    "                    a = char[j] + 1\n",
    "                else:\n",
    "                    a = (char[j] + char[j+1]) / 2\n",
    "                d = np.sign(integral)\n",
    "    ### Your Code Here ###\n",
    "\n",
    "    return k, a, d\n",
    "\n",
    "\n",
    "def decision_stump_error(X, y, k, a, d, w):\n",
    "    '''\n",
    "    decision_stump_error returns error of the given stump\n",
    "    Input\n",
    "        X : n * p matrix, each row a sample\n",
    "        y : (n, ) vector, each row a label\n",
    "        k : selected dimension of features\n",
    "        a : selected threshold for feature-k\n",
    "        d : 1 or -1\n",
    "    Output\n",
    "        e : number of errors of the given stump \n",
    "    '''\n",
    "    p = ((X[:, k] <= a).astype('float') - 0.5) * 2 * d # predicted label\n",
    "    e = np.sum((p.astype('int') != y) * w)\n",
    "\n",
    "    return e\n",
    "\n",
    "\n",
    "def update_weights(X, y, k, a, d, w, alpha):\n",
    "    '''\n",
    "    update_weights update the weights with the recent classifier\n",
    "    \n",
    "    Input\n",
    "        X        : n * p matrix, each row a sample\n",
    "        y        : (n, ) vector, each row a label\n",
    "        k        : selected dimension of features\n",
    "        a        : selected threshold for feature-k\n",
    "        d        : 1 or -1\n",
    "        w        : (n, ) vector, old weights\n",
    "        alpha    : weights of the classifiers\n",
    "    \n",
    "    Output\n",
    "        w_update : (n, ) vector, the updated weights\n",
    "    '''\n",
    "\n",
    "    ### Your Code Here ###\n",
    "    p = ((X[:, k] <= a).astype('float') - 0.5) * 2 * d # predicted label\n",
    "    w_update = w * np.exp(((p.astype(int) != y).astype(float) - 0.5) * 2 * alpha)\n",
    "    w_update /= w_update.sum()\n",
    "    ### Your Code Here ###\n",
    "    \n",
    "    return w_update\n",
    "\n",
    "\n",
    "def adaboost_error(X, y, k, a, d, alpha):\n",
    "    '''\n",
    "    adaboost_error: returns the final error rate of a whole adaboost\n",
    "    \n",
    "    Input\n",
    "        X     : n * p matrix, each row a sample\n",
    "        y     : (n, ) vector, each row a label\n",
    "        k     : (iter, ) vector,  selected dimension of features\n",
    "        a     : (iter, ) vector, selected threshold for feature-k\n",
    "        d     : (iter, ) vector, 1 or -1\n",
    "        alpha : (iter, ) vector, weights of the classifiers\n",
    "    Output\n",
    "        e     : error rate  \n",
    "    '''\n",
    "\n",
    "    ### Your Code Here ###\n",
    "    iters = k.shape[0]\n",
    "    p = np.zeros(y.size)\n",
    "    for i in range(iters):\n",
    "        p += alpha[i] * ((X[:, k[i]] <= a[i]).astype('float') - 0.5) * 2 * d[i] # predicted label\n",
    "    p = ((p >= 0).astype(int) - 0.5) * 2\n",
    "    e = (p != y).sum() / y.size\n",
    "    ### Your Code Here ###\n",
    "    \n",
    "    return e\n"
   ]
  },
  {
   "source": [
    "## Run AdaBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "new decision stump k:3 a:0.101121, d:1, e:0.381000\n",
      "weak learner error rate: 0.381000\n",
      "adaboost error rate: 0.381000\n",
      "test error rate: 0.409000\n",
      "\n",
      "new decision stump k:0 a:0.200388, d:1, e:0.378095\n",
      "weak learner error rate: 0.378095\n",
      "adaboost error rate: 0.385000\n",
      "test error rate: 0.380000\n",
      "\n",
      "new decision stump k:12 a:0.354067, d:-1, e:0.336975\n",
      "weak learner error rate: 0.336975\n",
      "adaboost error rate: 0.317000\n",
      "test error rate: 0.310000\n",
      "\n",
      "new decision stump k:20 a:0.206706, d:1, e:0.394229\n",
      "weak learner error rate: 0.394229\n",
      "adaboost error rate: 0.312000\n",
      "test error rate: 0.300000\n",
      "\n",
      "new decision stump k:18 a:0.227233, d:1, e:0.401915\n",
      "weak learner error rate: 0.401915\n",
      "adaboost error rate: 0.282000\n",
      "test error rate: 0.301000\n",
      "\n",
      "new decision stump k:22 a:-0.420288, d:-1, e:0.333021\n",
      "weak learner error rate: 0.333021\n",
      "adaboost error rate: 0.245000\n",
      "test error rate: 0.292000\n",
      "\n",
      "new decision stump k:5 a:0.529665, d:-1, e:0.362794\n",
      "weak learner error rate: 0.362794\n",
      "adaboost error rate: 0.231000\n",
      "test error rate: 0.284000\n",
      "\n",
      "new decision stump k:23 a:0.899694, d:1, e:0.414528\n",
      "weak learner error rate: 0.414528\n",
      "adaboost error rate: 0.233000\n",
      "test error rate: 0.272000\n",
      "\n",
      "new decision stump k:15 a:0.361261, d:-1, e:0.362600\n",
      "weak learner error rate: 0.362600\n",
      "adaboost error rate: 0.210000\n",
      "test error rate: 0.280000\n",
      "\n",
      "new decision stump k:0 a:-0.387046, d:1, e:0.419965\n",
      "weak learner error rate: 0.419965\n",
      "adaboost error rate: 0.207000\n",
      "test error rate: 0.248000\n",
      "\n",
      "new decision stump k:3 a:0.784952, d:1, e:0.416271\n",
      "weak learner error rate: 0.416271\n",
      "adaboost error rate: 0.210000\n",
      "test error rate: 0.265000\n",
      "\n",
      "new decision stump k:4 a:-0.638021, d:-1, e:0.372823\n",
      "weak learner error rate: 0.372823\n",
      "adaboost error rate: 0.190000\n",
      "test error rate: 0.248000\n",
      "\n",
      "new decision stump k:12 a:0.872342, d:-1, e:0.367540\n",
      "weak learner error rate: 0.367540\n",
      "adaboost error rate: 0.184000\n",
      "test error rate: 0.242000\n",
      "\n",
      "new decision stump k:11 a:0.862730, d:1, e:0.422731\n",
      "weak learner error rate: 0.422731\n",
      "adaboost error rate: 0.178000\n",
      "test error rate: 0.236000\n",
      "\n",
      "new decision stump k:22 a:0.498258, d:-1, e:0.377200\n",
      "weak learner error rate: 0.377200\n",
      "adaboost error rate: 0.171000\n",
      "test error rate: 0.230000\n",
      "\n",
      "new decision stump k:0 a:0.934825, d:1, e:0.421104\n",
      "weak learner error rate: 0.421104\n",
      "adaboost error rate: 0.179000\n",
      "test error rate: 0.233000\n",
      "\n",
      "new decision stump k:12 a:-0.395667, d:-1, e:0.393432\n",
      "weak learner error rate: 0.393432\n",
      "adaboost error rate: 0.162000\n",
      "test error rate: 0.211000\n",
      "\n",
      "new decision stump k:24 a:0.267302, d:-1, e:0.383861\n",
      "weak learner error rate: 0.383861\n",
      "adaboost error rate: 0.165000\n",
      "test error rate: 0.214000\n",
      "\n",
      "new decision stump k:15 a:-0.697337, d:-1, e:0.402248\n",
      "weak learner error rate: 0.402248\n",
      "adaboost error rate: 0.158000\n",
      "test error rate: 0.215000\n",
      "\n",
      "new decision stump k:21 a:1.070543, d:-1, e:0.375756\n",
      "weak learner error rate: 0.375756\n",
      "adaboost error rate: 0.144000\n",
      "test error rate: 0.197000\n",
      "\n",
      "new decision stump k:4 a:-0.109869, d:-1, e:0.399957\n",
      "weak learner error rate: 0.399957\n",
      "adaboost error rate: 0.149000\n",
      "test error rate: 0.198000\n",
      "\n",
      "new decision stump k:12 a:-0.987326, d:-1, e:0.404198\n",
      "weak learner error rate: 0.404198\n",
      "adaboost error rate: 0.138000\n",
      "test error rate: 0.196000\n",
      "\n",
      "new decision stump k:10 a:1.040938, d:-1, e:0.389705\n",
      "weak learner error rate: 0.389705\n",
      "adaboost error rate: 0.129000\n",
      "test error rate: 0.176000\n",
      "\n",
      "new decision stump k:3 a:-0.227058, d:1, e:0.411533\n",
      "weak learner error rate: 0.411533\n",
      "adaboost error rate: 0.122000\n",
      "test error rate: 0.184000\n",
      "\n",
      "new decision stump k:20 a:1.054188, d:1, e:0.413963\n",
      "weak learner error rate: 0.413963\n",
      "adaboost error rate: 0.123000\n",
      "test error rate: 0.183000\n",
      "\n",
      "new decision stump k:5 a:-0.163185, d:-1, e:0.401360\n",
      "weak learner error rate: 0.401360\n",
      "adaboost error rate: 0.108000\n",
      "test error rate: 0.180000\n",
      "\n",
      "new decision stump k:8 a:0.317906, d:-1, e:0.407383\n",
      "weak learner error rate: 0.407383\n",
      "adaboost error rate: 0.108000\n",
      "test error rate: 0.178000\n",
      "\n",
      "new decision stump k:22 a:0.254737, d:-1, e:0.425894\n",
      "weak learner error rate: 0.425894\n",
      "adaboost error rate: 0.107000\n",
      "test error rate: 0.182000\n",
      "\n",
      "new decision stump k:18 a:0.481482, d:1, e:0.413573\n",
      "weak learner error rate: 0.413573\n",
      "adaboost error rate: 0.112000\n",
      "test error rate: 0.178000\n",
      "\n",
      "new decision stump k:21 a:-0.021101, d:-1, e:0.428628\n",
      "weak learner error rate: 0.428628\n",
      "adaboost error rate: 0.111000\n",
      "test error rate: 0.178000\n",
      "\n",
      "new decision stump k:15 a:1.116390, d:-1, e:0.424087\n",
      "weak learner error rate: 0.424087\n",
      "adaboost error rate: 0.110000\n",
      "test error rate: 0.172000\n",
      "\n",
      "new decision stump k:0 a:0.302890, d:1, e:0.416932\n",
      "weak learner error rate: 0.416932\n",
      "adaboost error rate: 0.101000\n",
      "test error rate: 0.174000\n",
      "\n",
      "new decision stump k:20 a:-0.204279, d:1, e:0.412716\n",
      "weak learner error rate: 0.412716\n",
      "adaboost error rate: 0.105000\n",
      "test error rate: 0.160000\n",
      "\n",
      "new decision stump k:23 a:-0.154338, d:1, e:0.410497\n",
      "weak learner error rate: 0.410497\n",
      "adaboost error rate: 0.100000\n",
      "test error rate: 0.164000\n",
      "\n",
      "new decision stump k:13 a:1.114835, d:1, e:0.420858\n",
      "weak learner error rate: 0.420858\n",
      "adaboost error rate: 0.104000\n",
      "test error rate: 0.167000\n",
      "\n",
      "new decision stump k:12 a:-0.072542, d:-1, e:0.420953\n",
      "weak learner error rate: 0.420953\n",
      "adaboost error rate: 0.105000\n",
      "test error rate: 0.166000\n",
      "\n",
      "new decision stump k:5 a:1.153291, d:-1, e:0.420909\n",
      "weak learner error rate: 0.420909\n",
      "adaboost error rate: 0.101000\n",
      "test error rate: 0.145000\n",
      "\n",
      "new decision stump k:11 a:0.163825, d:1, e:0.421478\n",
      "weak learner error rate: 0.421478\n",
      "adaboost error rate: 0.094000\n",
      "test error rate: 0.156000\n",
      "\n",
      "new decision stump k:3 a:-0.520948, d:1, e:0.430735\n",
      "weak learner error rate: 0.430735\n",
      "adaboost error rate: 0.097000\n",
      "test error rate: 0.152000\n",
      "\n",
      "new decision stump k:18 a:1.075988, d:1, e:0.408650\n",
      "weak learner error rate: 0.408650\n",
      "adaboost error rate: 0.087000\n",
      "test error rate: 0.160000\n",
      "\n",
      "new decision stump k:4 a:0.472382, d:-1, e:0.421886\n",
      "weak learner error rate: 0.421886\n",
      "adaboost error rate: 0.090000\n",
      "test error rate: 0.152000\n",
      "\n",
      "new decision stump k:0 a:-0.873609, d:1, e:0.430012\n",
      "weak learner error rate: 0.430012\n",
      "adaboost error rate: 0.093000\n",
      "test error rate: 0.150000\n",
      "\n",
      "new decision stump k:0 a:1.377029, d:1, e:0.416791\n",
      "weak learner error rate: 0.416791\n",
      "adaboost error rate: 0.087000\n",
      "test error rate: 0.141000\n",
      "\n",
      "new decision stump k:2 a:0.586073, d:-1, e:0.419344\n",
      "weak learner error rate: 0.419344\n",
      "adaboost error rate: 0.090000\n",
      "test error rate: 0.153000\n",
      "\n",
      "new decision stump k:22 a:-0.934547, d:-1, e:0.406954\n",
      "weak learner error rate: 0.406954\n",
      "adaboost error rate: 0.080000\n",
      "test error rate: 0.156000\n",
      "\n",
      "new decision stump k:12 a:1.130676, d:-1, e:0.404964\n",
      "weak learner error rate: 0.404964\n",
      "adaboost error rate: 0.088000\n",
      "test error rate: 0.151000\n",
      "\n",
      "new decision stump k:3 a:0.377404, d:1, e:0.432517\n",
      "weak learner error rate: 0.432517\n",
      "adaboost error rate: 0.082000\n",
      "test error rate: 0.150000\n",
      "\n",
      "new decision stump k:15 a:-0.854910, d:-1, e:0.394925\n",
      "weak learner error rate: 0.394925\n",
      "adaboost error rate: 0.088000\n",
      "test error rate: 0.155000\n",
      "\n",
      "new decision stump k:5 a:0.457624, d:-1, e:0.413557\n",
      "weak learner error rate: 0.413557\n",
      "adaboost error rate: 0.080000\n",
      "test error rate: 0.146000\n",
      "\n",
      "new decision stump k:24 a:-0.681386, d:-1, e:0.411232\n",
      "weak learner error rate: 0.411232\n",
      "adaboost error rate: 0.078000\n",
      "test error rate: 0.159000\n",
      "\n",
      "new decision stump k:22 a:1.556315, d:-1, e:0.401014\n",
      "weak learner error rate: 0.401014\n",
      "adaboost error rate: 0.075000\n",
      "test error rate: 0.147000\n",
      "\n",
      "new decision stump k:13 a:0.527240, d:1, e:0.434374\n",
      "weak learner error rate: 0.434374\n",
      "adaboost error rate: 0.074000\n",
      "test error rate: 0.152000\n",
      "\n",
      "new decision stump k:12 a:-1.234975, d:-1, e:0.411158\n",
      "weak learner error rate: 0.411158\n",
      "adaboost error rate: 0.068000\n",
      "test error rate: 0.148000\n",
      "\n",
      "new decision stump k:4 a:1.227542, d:-1, e:0.397471\n",
      "weak learner error rate: 0.397471\n",
      "adaboost error rate: 0.065000\n",
      "test error rate: 0.136000\n",
      "\n",
      "new decision stump k:5 a:-0.939140, d:-1, e:0.420048\n",
      "weak learner error rate: 0.420048\n",
      "adaboost error rate: 0.060000\n",
      "test error rate: 0.134000\n",
      "\n",
      "new decision stump k:12 a:1.002660, d:-1, e:0.419375\n",
      "weak learner error rate: 0.419375\n",
      "adaboost error rate: 0.064000\n",
      "test error rate: 0.133000\n",
      "\n",
      "new decision stump k:20 a:1.043791, d:1, e:0.433843\n",
      "weak learner error rate: 0.433843\n",
      "adaboost error rate: 0.057000\n",
      "test error rate: 0.130000\n",
      "\n",
      "new decision stump k:22 a:0.310932, d:-1, e:0.419488\n",
      "weak learner error rate: 0.419488\n",
      "adaboost error rate: 0.064000\n",
      "test error rate: 0.134000\n",
      "\n",
      "new decision stump k:10 a:0.244583, d:-1, e:0.426939\n",
      "weak learner error rate: 0.426939\n",
      "adaboost error rate: 0.065000\n",
      "test error rate: 0.128000\n",
      "\n",
      "new decision stump k:20 a:-0.139951, d:1, e:0.437903\n",
      "weak learner error rate: 0.437903\n",
      "adaboost error rate: 0.064000\n",
      "test error rate: 0.125000\n",
      "\n",
      "new decision stump k:0 a:0.737236, d:1, e:0.436483\n",
      "weak learner error rate: 0.436483\n",
      "adaboost error rate: 0.060000\n",
      "test error rate: 0.130000\n",
      "\n",
      "new decision stump k:24 a:0.062695, d:-1, e:0.439255\n",
      "weak learner error rate: 0.439255\n",
      "adaboost error rate: 0.059000\n",
      "test error rate: 0.122000\n",
      "\n",
      "new decision stump k:1 a:0.257888, d:-1, e:0.436894\n",
      "weak learner error rate: 0.436894\n",
      "adaboost error rate: 0.051000\n",
      "test error rate: 0.124000\n",
      "\n",
      "new decision stump k:12 a:-1.268308, d:-1, e:0.434884\n",
      "weak learner error rate: 0.434884\n",
      "adaboost error rate: 0.051000\n",
      "test error rate: 0.127000\n",
      "\n",
      "new decision stump k:15 a:1.540019, d:-1, e:0.410078\n",
      "weak learner error rate: 0.410078\n",
      "adaboost error rate: 0.054000\n",
      "test error rate: 0.124000\n",
      "\n",
      "new decision stump k:23 a:-0.716626, d:1, e:0.442537\n",
      "weak learner error rate: 0.442537\n",
      "adaboost error rate: 0.060000\n",
      "test error rate: 0.126000\n",
      "\n",
      "new decision stump k:3 a:1.571166, d:1, e:0.431757\n",
      "weak learner error rate: 0.431757\n",
      "adaboost error rate: 0.048000\n",
      "test error rate: 0.125000\n",
      "\n",
      "new decision stump k:6 a:0.624355, d:-1, e:0.437948\n",
      "weak learner error rate: 0.437948\n",
      "adaboost error rate: 0.054000\n",
      "test error rate: 0.120000\n",
      "\n",
      "new decision stump k:3 a:-0.580466, d:1, e:0.440521\n",
      "weak learner error rate: 0.440521\n",
      "adaboost error rate: 0.055000\n",
      "test error rate: 0.120000\n",
      "\n",
      "new decision stump k:11 a:1.670859, d:1, e:0.432717\n",
      "weak learner error rate: 0.432717\n",
      "adaboost error rate: 0.049000\n",
      "test error rate: 0.122000\n",
      "\n",
      "new decision stump k:4 a:-0.824220, d:-1, e:0.439520\n",
      "weak learner error rate: 0.439520\n",
      "adaboost error rate: 0.046000\n",
      "test error rate: 0.127000\n",
      "\n",
      "new decision stump k:12 a:1.130676, d:-1, e:0.415153\n",
      "weak learner error rate: 0.415153\n",
      "adaboost error rate: 0.052000\n",
      "test error rate: 0.122000\n",
      "\n",
      "new decision stump k:0 a:-0.072454, d:1, e:0.443667\n",
      "weak learner error rate: 0.443667\n",
      "adaboost error rate: 0.051000\n",
      "test error rate: 0.126000\n",
      "\n",
      "new decision stump k:18 a:0.936350, d:1, e:0.449441\n",
      "weak learner error rate: 0.449441\n",
      "adaboost error rate: 0.047000\n",
      "test error rate: 0.131000\n",
      "\n",
      "new decision stump k:22 a:1.213111, d:-1, e:0.445816\n",
      "weak learner error rate: 0.445816\n",
      "adaboost error rate: 0.051000\n",
      "test error rate: 0.128000\n",
      "\n",
      "new decision stump k:9 a:0.854521, d:1, e:0.445862\n",
      "weak learner error rate: 0.445862\n",
      "adaboost error rate: 0.047000\n",
      "test error rate: 0.127000\n",
      "\n",
      "new decision stump k:12 a:-0.377383, d:-1, e:0.438104\n",
      "weak learner error rate: 0.438104\n",
      "adaboost error rate: 0.044000\n",
      "test error rate: 0.129000\n",
      "\n",
      "new decision stump k:5 a:1.326342, d:-1, e:0.437814\n",
      "weak learner error rate: 0.437814\n",
      "adaboost error rate: 0.051000\n",
      "test error rate: 0.128000\n",
      "\n",
      "new decision stump k:20 a:0.554391, d:1, e:0.441205\n",
      "weak learner error rate: 0.441205\n",
      "adaboost error rate: 0.045000\n",
      "test error rate: 0.123000\n",
      "\n",
      "new decision stump k:15 a:-0.718729, d:-1, e:0.426524\n",
      "weak learner error rate: 0.426524\n",
      "adaboost error rate: 0.045000\n",
      "test error rate: 0.128000\n",
      "\n",
      "new decision stump k:22 a:1.556315, d:-1, e:0.429116\n",
      "weak learner error rate: 0.429116\n",
      "adaboost error rate: 0.048000\n",
      "test error rate: 0.120000\n",
      "\n",
      "new decision stump k:3 a:0.595481, d:1, e:0.445055\n",
      "weak learner error rate: 0.445055\n",
      "adaboost error rate: 0.048000\n",
      "test error rate: 0.124000\n",
      "\n",
      "new decision stump k:22 a:-0.934547, d:-1, e:0.429002\n",
      "weak learner error rate: 0.429002\n",
      "adaboost error rate: 0.036000\n",
      "test error rate: 0.130000\n",
      "\n",
      "new decision stump k:4 a:1.603861, d:-1, e:0.426029\n",
      "weak learner error rate: 0.426029\n",
      "adaboost error rate: 0.047000\n",
      "test error rate: 0.120000\n",
      "\n",
      "new decision stump k:13 a:1.287796, d:1, e:0.448768\n",
      "weak learner error rate: 0.448768\n",
      "adaboost error rate: 0.039000\n",
      "test error rate: 0.127000\n",
      "\n",
      "new decision stump k:14 a:0.258979, d:-1, e:0.441859\n",
      "weak learner error rate: 0.441859\n",
      "adaboost error rate: 0.041000\n",
      "test error rate: 0.123000\n",
      "\n",
      "new decision stump k:21 a:-0.380600, d:-1, e:0.438752\n",
      "weak learner error rate: 0.438752\n",
      "adaboost error rate: 0.036000\n",
      "test error rate: 0.126000\n",
      "\n",
      "new decision stump k:5 a:1.326342, d:-1, e:0.438384\n",
      "weak learner error rate: 0.438384\n",
      "adaboost error rate: 0.042000\n",
      "test error rate: 0.121000\n",
      "\n",
      "new decision stump k:23 a:1.011511, d:1, e:0.444084\n",
      "weak learner error rate: 0.444084\n",
      "adaboost error rate: 0.036000\n",
      "test error rate: 0.122000\n",
      "\n",
      "new decision stump k:19 a:-0.410241, d:-1, e:0.443572\n",
      "weak learner error rate: 0.443572\n",
      "adaboost error rate: 0.033000\n",
      "test error rate: 0.124000\n",
      "\n",
      "new decision stump k:24 a:1.095939, d:-1, e:0.434912\n",
      "weak learner error rate: 0.434912\n",
      "adaboost error rate: 0.036000\n",
      "test error rate: 0.117000\n",
      "\n",
      "new decision stump k:12 a:-0.987326, d:-1, e:0.429653\n",
      "weak learner error rate: 0.429653\n",
      "adaboost error rate: 0.032000\n",
      "test error rate: 0.122000\n",
      "\n",
      "new decision stump k:15 a:0.925194, d:-1, e:0.430155\n",
      "weak learner error rate: 0.430155\n",
      "adaboost error rate: 0.036000\n",
      "test error rate: 0.110000\n",
      "\n",
      "new decision stump k:5 a:-0.939140, d:-1, e:0.432033\n",
      "weak learner error rate: 0.432033\n",
      "adaboost error rate: 0.034000\n",
      "test error rate: 0.112000\n",
      "\n",
      "new decision stump k:4 a:0.284898, d:-1, e:0.435283\n",
      "weak learner error rate: 0.435283\n",
      "adaboost error rate: 0.037000\n",
      "test error rate: 0.114000\n",
      "\n",
      "new decision stump k:12 a:1.117837, d:-1, e:0.447178\n",
      "weak learner error rate: 0.447178\n",
      "adaboost error rate: 0.038000\n",
      "test error rate: 0.108000\n",
      "\n",
      "new decision stump k:0 a:1.377029, d:1, e:0.443228\n",
      "weak learner error rate: 0.443228\n",
      "adaboost error rate: 0.036000\n",
      "test error rate: 0.111000\n",
      "\n",
      "new decision stump k:21 a:1.397827, d:-1, e:0.444477\n",
      "weak learner error rate: 0.444477\n",
      "adaboost error rate: 0.035000\n",
      "test error rate: 0.106000\n",
      "\n",
      "new decision stump k:11 a:0.044307, d:1, e:0.441956\n",
      "weak learner error rate: 0.441956\n",
      "adaboost error rate: 0.039000\n",
      "test error rate: 0.106000\n",
      "\n",
      "new decision stump k:0 a:-0.593297, d:1, e:0.451309\n",
      "weak learner error rate: 0.451309\n",
      "adaboost error rate: 0.038000\n",
      "test error rate: 0.109000\n",
      "\n",
      "new decision stump k:3 a:1.571166, d:1, e:0.435515\n",
      "weak learner error rate: 0.435515\n",
      "adaboost error rate: 0.032000\n",
      "test error rate: 0.108000\n",
      "\n",
      "new decision stump k:22 a:-0.061007, d:-1, e:0.442463\n",
      "weak learner error rate: 0.442463\n",
      "adaboost error rate: 0.033000\n",
      "test error rate: 0.116000\n",
      "\n",
      "new decision stump k:12 a:0.526309, d:-1, e:0.445177\n",
      "weak learner error rate: 0.445177\n",
      "adaboost error rate: 0.031000\n",
      "test error rate: 0.110000\n",
      "\n",
      "new decision stump k:23 a:-1.060782, d:1, e:0.441858\n",
      "weak learner error rate: 0.441858\n",
      "adaboost error rate: 0.031000\n",
      "test error rate: 0.105000\n",
      "\n",
      "new decision stump k:18 a:1.418430, d:1, e:0.432644\n",
      "weak learner error rate: 0.432644\n",
      "adaboost error rate: 0.031000\n",
      "test error rate: 0.112000\n",
      "\n",
      "new decision stump k:10 a:-0.706152, d:-1, e:0.442986\n",
      "weak learner error rate: 0.442986\n",
      "adaboost error rate: 0.029000\n",
      "test error rate: 0.111000\n",
      "\n",
      "new decision stump k:22 a:1.556315, d:-1, e:0.431520\n",
      "weak learner error rate: 0.431520\n",
      "adaboost error rate: 0.028000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:20 a:-0.139951, d:1, e:0.445174\n",
      "weak learner error rate: 0.445174\n",
      "adaboost error rate: 0.029000\n",
      "test error rate: 0.105000\n",
      "\n",
      "new decision stump k:3 a:0.377404, d:1, e:0.445530\n",
      "weak learner error rate: 0.445530\n",
      "adaboost error rate: 0.031000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:24 a:-0.658157, d:-1, e:0.433922\n",
      "weak learner error rate: 0.433922\n",
      "adaboost error rate: 0.028000\n",
      "test error rate: 0.104000\n",
      "\n",
      "new decision stump k:5 a:0.313816, d:-1, e:0.437749\n",
      "weak learner error rate: 0.437749\n",
      "adaboost error rate: 0.028000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:2 a:-0.229374, d:-1, e:0.439740\n",
      "weak learner error rate: 0.439740\n",
      "adaboost error rate: 0.025000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:4 a:-0.574586, d:-1, e:0.446425\n",
      "weak learner error rate: 0.446425\n",
      "adaboost error rate: 0.030000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:12 a:1.190079, d:-1, e:0.434639\n",
      "weak learner error rate: 0.434639\n",
      "adaboost error rate: 0.028000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:0 a:0.377479, d:1, e:0.438039\n",
      "weak learner error rate: 0.438039\n",
      "adaboost error rate: 0.028000\n",
      "test error rate: 0.105000\n",
      "\n",
      "new decision stump k:15 a:-0.950660, d:-1, e:0.442209\n",
      "weak learner error rate: 0.442209\n",
      "adaboost error rate: 0.025000\n",
      "test error rate: 0.114000\n",
      "\n",
      "new decision stump k:19 a:1.005201, d:-1, e:0.435520\n",
      "weak learner error rate: 0.435520\n",
      "adaboost error rate: 0.030000\n",
      "test error rate: 0.104000\n",
      "\n",
      "new decision stump k:12 a:-1.268308, d:-1, e:0.436686\n",
      "weak learner error rate: 0.436686\n",
      "adaboost error rate: 0.023000\n",
      "test error rate: 0.112000\n",
      "\n",
      "new decision stump k:15 a:1.540019, d:-1, e:0.425295\n",
      "weak learner error rate: 0.425295\n",
      "adaboost error rate: 0.026000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:18 a:-0.664742, d:1, e:0.447329\n",
      "weak learner error rate: 0.447329\n",
      "adaboost error rate: 0.022000\n",
      "test error rate: 0.104000\n",
      "\n",
      "new decision stump k:0 a:1.377029, d:1, e:0.436352\n",
      "weak learner error rate: 0.436352\n",
      "adaboost error rate: 0.024000\n",
      "test error rate: 0.108000\n",
      "\n",
      "new decision stump k:12 a:-0.129760, d:-1, e:0.440665\n",
      "weak learner error rate: 0.440665\n",
      "adaboost error rate: 0.020000\n",
      "test error rate: 0.109000\n",
      "\n",
      "new decision stump k:7 a:0.365792, d:-1, e:0.441579\n",
      "weak learner error rate: 0.441579\n",
      "adaboost error rate: 0.020000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:3 a:-1.097988, d:1, e:0.432903\n",
      "weak learner error rate: 0.432903\n",
      "adaboost error rate: 0.021000\n",
      "test error rate: 0.095000\n",
      "\n",
      "new decision stump k:20 a:1.043791, d:1, e:0.426310\n",
      "weak learner error rate: 0.426310\n",
      "adaboost error rate: 0.017000\n",
      "test error rate: 0.108000\n",
      "\n",
      "new decision stump k:22 a:-0.815403, d:-1, e:0.444168\n",
      "weak learner error rate: 0.444168\n",
      "adaboost error rate: 0.020000\n",
      "test error rate: 0.107000\n",
      "\n",
      "new decision stump k:21 a:1.397827, d:-1, e:0.437112\n",
      "weak learner error rate: 0.437112\n",
      "adaboost error rate: 0.020000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:11 a:-0.510418, d:1, e:0.449828\n",
      "weak learner error rate: 0.449828\n",
      "adaboost error rate: 0.018000\n",
      "test error rate: 0.105000\n",
      "\n",
      "new decision stump k:13 a:1.269906, d:1, e:0.438178\n",
      "weak learner error rate: 0.438178\n",
      "adaboost error rate: 0.017000\n",
      "test error rate: 0.111000\n",
      "\n",
      "new decision stump k:16 a:0.012072, d:-1, e:0.445908\n",
      "weak learner error rate: 0.445908\n",
      "adaboost error rate: 0.016000\n",
      "test error rate: 0.112000\n",
      "\n",
      "new decision stump k:21 a:-1.026261, d:-1, e:0.447037\n",
      "weak learner error rate: 0.447037\n",
      "adaboost error rate: 0.015000\n",
      "test error rate: 0.113000\n",
      "\n",
      "new decision stump k:5 a:1.326342, d:-1, e:0.429802\n",
      "weak learner error rate: 0.429802\n",
      "adaboost error rate: 0.015000\n",
      "test error rate: 0.111000\n",
      "\n",
      "new decision stump k:0 a:-0.467942, d:1, e:0.451462\n",
      "weak learner error rate: 0.451462\n",
      "adaboost error rate: 0.018000\n",
      "test error rate: 0.105000\n",
      "\n",
      "new decision stump k:18 a:0.936350, d:1, e:0.449939\n",
      "weak learner error rate: 0.449939\n",
      "adaboost error rate: 0.015000\n",
      "test error rate: 0.109000\n",
      "\n",
      "new decision stump k:4 a:-0.571791, d:-1, e:0.447763\n",
      "weak learner error rate: 0.447763\n",
      "adaboost error rate: 0.014000\n",
      "test error rate: 0.104000\n",
      "\n",
      "new decision stump k:24 a:1.095939, d:-1, e:0.442075\n",
      "weak learner error rate: 0.442075\n",
      "adaboost error rate: 0.014000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:23 a:-1.060782, d:1, e:0.451394\n",
      "weak learner error rate: 0.451394\n",
      "adaboost error rate: 0.015000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:3 a:1.571166, d:1, e:0.437166\n",
      "weak learner error rate: 0.437166\n",
      "adaboost error rate: 0.012000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:21 a:0.192554, d:-1, e:0.445760\n",
      "weak learner error rate: 0.445760\n",
      "adaboost error rate: 0.014000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:22 a:0.205182, d:-1, e:0.450727\n",
      "weak learner error rate: 0.450727\n",
      "adaboost error rate: 0.014000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:12 a:-0.987326, d:-1, e:0.444379\n",
      "weak learner error rate: 0.444379\n",
      "adaboost error rate: 0.014000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:4 a:1.227542, d:-1, e:0.432579\n",
      "weak learner error rate: 0.432579\n",
      "adaboost error rate: 0.014000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:0 a:-1.443335, d:1, e:0.456334\n",
      "weak learner error rate: 0.456334\n",
      "adaboost error rate: 0.015000\n",
      "test error rate: 0.095000\n",
      "\n",
      "new decision stump k:23 a:1.534776, d:1, e:0.431430\n",
      "weak learner error rate: 0.431430\n",
      "adaboost error rate: 0.013000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:10 a:0.283584, d:-1, e:0.445119\n",
      "weak learner error rate: 0.445119\n",
      "adaboost error rate: 0.016000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:5 a:-0.004725, d:-1, e:0.443401\n",
      "weak learner error rate: 0.443401\n",
      "adaboost error rate: 0.013000\n",
      "test error rate: 0.104000\n",
      "\n",
      "new decision stump k:3 a:-0.580466, d:1, e:0.446363\n",
      "weak learner error rate: 0.446363\n",
      "adaboost error rate: 0.014000\n",
      "test error rate: 0.100000\n",
      "\n",
      "new decision stump k:0 a:1.377029, d:1, e:0.446020\n",
      "weak learner error rate: 0.446020\n",
      "adaboost error rate: 0.013000\n",
      "test error rate: 0.109000\n",
      "\n",
      "new decision stump k:12 a:0.872342, d:-1, e:0.449605\n",
      "weak learner error rate: 0.449605\n",
      "adaboost error rate: 0.014000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:20 a:-0.139951, d:1, e:0.447762\n",
      "weak learner error rate: 0.447762\n",
      "adaboost error rate: 0.011000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:11 a:1.130465, d:1, e:0.450248\n",
      "weak learner error rate: 0.450248\n",
      "adaboost error rate: 0.015000\n",
      "test error rate: 0.107000\n",
      "\n",
      "new decision stump k:24 a:0.009742, d:-1, e:0.448215\n",
      "weak learner error rate: 0.448215\n",
      "adaboost error rate: 0.015000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:22 a:-1.343717, d:-1, e:0.451559\n",
      "weak learner error rate: 0.451559\n",
      "adaboost error rate: 0.016000\n",
      "test error rate: 0.106000\n",
      "\n",
      "new decision stump k:22 a:1.556315, d:-1, e:0.427388\n",
      "weak learner error rate: 0.427388\n",
      "adaboost error rate: 0.013000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:3 a:0.862222, d:1, e:0.455698\n",
      "weak learner error rate: 0.455698\n",
      "adaboost error rate: 0.014000\n",
      "test error rate: 0.100000\n",
      "\n",
      "new decision stump k:15 a:0.347501, d:-1, e:0.451510\n",
      "weak learner error rate: 0.451510\n",
      "adaboost error rate: 0.011000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:0 a:-1.201886, d:1, e:0.446573\n",
      "weak learner error rate: 0.446573\n",
      "adaboost error rate: 0.007000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:13 a:1.327285, d:1, e:0.435088\n",
      "weak learner error rate: 0.435088\n",
      "adaboost error rate: 0.011000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:4 a:0.284898, d:-1, e:0.451087\n",
      "weak learner error rate: 0.451087\n",
      "adaboost error rate: 0.010000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:12 a:-1.268308, d:-1, e:0.439794\n",
      "weak learner error rate: 0.439794\n",
      "adaboost error rate: 0.012000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:12 a:1.117837, d:-1, e:0.427365\n",
      "weak learner error rate: 0.427365\n",
      "adaboost error rate: 0.008000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:0 a:0.128292, d:1, e:0.455854\n",
      "weak learner error rate: 0.455854\n",
      "adaboost error rate: 0.010000\n",
      "test error rate: 0.104000\n",
      "\n",
      "new decision stump k:3 a:-1.231435, d:1, e:0.453885\n",
      "weak learner error rate: 0.453885\n",
      "adaboost error rate: 0.008000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:20 a:1.043791, d:1, e:0.434723\n",
      "weak learner error rate: 0.434723\n",
      "adaboost error rate: 0.009000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:22 a:-0.934547, d:-1, e:0.447604\n",
      "weak learner error rate: 0.447604\n",
      "adaboost error rate: 0.012000\n",
      "test error rate: 0.104000\n",
      "\n",
      "new decision stump k:5 a:0.777474, d:-1, e:0.440565\n",
      "weak learner error rate: 0.440565\n",
      "adaboost error rate: 0.008000\n",
      "test error rate: 0.104000\n",
      "\n",
      "new decision stump k:18 a:-0.561619, d:1, e:0.449034\n",
      "weak learner error rate: 0.449034\n",
      "adaboost error rate: 0.010000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:23 a:1.011511, d:1, e:0.455274\n",
      "weak learner error rate: 0.455274\n",
      "adaboost error rate: 0.010000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:12 a:-0.098633, d:-1, e:0.447589\n",
      "weak learner error rate: 0.447589\n",
      "adaboost error rate: 0.011000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:15 a:-0.950660, d:-1, e:0.448188\n",
      "weak learner error rate: 0.448188\n",
      "adaboost error rate: 0.010000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:22 a:0.853709, d:-1, e:0.430323\n",
      "weak learner error rate: 0.430323\n",
      "adaboost error rate: 0.009000\n",
      "test error rate: 0.100000\n",
      "\n",
      "new decision stump k:24 a:-0.658157, d:-1, e:0.442527\n",
      "weak learner error rate: 0.442527\n",
      "adaboost error rate: 0.009000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:1 a:0.448128, d:-1, e:0.439068\n",
      "weak learner error rate: 0.439068\n",
      "adaboost error rate: 0.008000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:5 a:-0.738757, d:-1, e:0.456630\n",
      "weak learner error rate: 0.456630\n",
      "adaboost error rate: 0.009000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:10 a:1.408930, d:-1, e:0.444593\n",
      "weak learner error rate: 0.444593\n",
      "adaboost error rate: 0.004000\n",
      "test error rate: 0.095000\n",
      "\n",
      "new decision stump k:1 a:-0.733920, d:1, e:0.447652\n",
      "weak learner error rate: 0.447652\n",
      "adaboost error rate: 0.006000\n",
      "test error rate: 0.100000\n",
      "\n",
      "new decision stump k:0 a:1.064778, d:1, e:0.437005\n",
      "weak learner error rate: 0.437005\n",
      "adaboost error rate: 0.006000\n",
      "test error rate: 0.097000\n",
      "\n",
      "new decision stump k:20 a:-1.278869, d:1, e:0.441282\n",
      "weak learner error rate: 0.441282\n",
      "adaboost error rate: 0.005000\n",
      "test error rate: 0.100000\n",
      "\n",
      "new decision stump k:3 a:2.155925, d:1, e:0.442722\n",
      "weak learner error rate: 0.442722\n",
      "adaboost error rate: 0.006000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:12 a:0.409962, d:-1, e:0.453102\n",
      "weak learner error rate: 0.453102\n",
      "adaboost error rate: 0.006000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:3 a:-1.231435, d:1, e:0.453234\n",
      "weak learner error rate: 0.453234\n",
      "adaboost error rate: 0.005000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:18 a:1.418430, d:1, e:0.439631\n",
      "weak learner error rate: 0.439631\n",
      "adaboost error rate: 0.006000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:4 a:-1.056969, d:-1, e:0.454480\n",
      "weak learner error rate: 0.454480\n",
      "adaboost error rate: 0.007000\n",
      "test error rate: 0.105000\n",
      "\n",
      "new decision stump k:15 a:1.189373, d:-1, e:0.439425\n",
      "weak learner error rate: 0.439425\n",
      "adaboost error rate: 0.007000\n",
      "test error rate: 0.106000\n",
      "\n",
      "new decision stump k:0 a:-0.467942, d:1, e:0.449877\n",
      "weak learner error rate: 0.449877\n",
      "adaboost error rate: 0.005000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:3 a:0.415635, d:1, e:0.451912\n",
      "weak learner error rate: 0.451912\n",
      "adaboost error rate: 0.008000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:23 a:-1.060782, d:1, e:0.448942\n",
      "weak learner error rate: 0.448942\n",
      "adaboost error rate: 0.004000\n",
      "test error rate: 0.100000\n",
      "\n",
      "new decision stump k:11 a:2.447582, d:1, e:0.443776\n",
      "weak learner error rate: 0.443776\n",
      "adaboost error rate: 0.006000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:8 a:-0.036210, d:-1, e:0.456201\n",
      "weak learner error rate: 0.456201\n",
      "adaboost error rate: 0.005000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:2 a:0.586073, d:-1, e:0.457038\n",
      "weak learner error rate: 0.457038\n",
      "adaboost error rate: 0.003000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:17 a:0.033359, d:1, e:0.451454\n",
      "weak learner error rate: 0.451454\n",
      "adaboost error rate: 0.003000\n",
      "test error rate: 0.097000\n",
      "\n",
      "new decision stump k:20 a:0.315036, d:1, e:0.452159\n",
      "weak learner error rate: 0.452159\n",
      "adaboost error rate: 0.004000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:12 a:-1.268308, d:-1, e:0.451302\n",
      "weak learner error rate: 0.451302\n",
      "adaboost error rate: 0.007000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:21 a:1.421772, d:-1, e:0.429518\n",
      "weak learner error rate: 0.429518\n",
      "adaboost error rate: 0.002000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:18 a:0.294490, d:1, e:0.454209\n",
      "weak learner error rate: 0.454209\n",
      "adaboost error rate: 0.003000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:19 a:-0.585790, d:-1, e:0.447975\n",
      "weak learner error rate: 0.447975\n",
      "adaboost error rate: 0.004000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:22 a:0.100921, d:-1, e:0.447774\n",
      "weak learner error rate: 0.447774\n",
      "adaboost error rate: 0.002000\n",
      "test error rate: 0.092000\n",
      "\n",
      "new decision stump k:12 a:-0.402147, d:-1, e:0.454446\n",
      "weak learner error rate: 0.454446\n",
      "adaboost error rate: 0.004000\n",
      "test error rate: 0.100000\n",
      "\n",
      "new decision stump k:5 a:0.529665, d:-1, e:0.443017\n",
      "weak learner error rate: 0.443017\n",
      "adaboost error rate: 0.003000\n",
      "test error rate: 0.095000\n",
      "\n",
      "new decision stump k:0 a:-1.443335, d:1, e:0.453624\n",
      "weak learner error rate: 0.453624\n",
      "adaboost error rate: 0.002000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:0 a:1.498508, d:1, e:0.440025\n",
      "weak learner error rate: 0.440025\n",
      "adaboost error rate: 0.003000\n",
      "test error rate: 0.094000\n",
      "\n",
      "new decision stump k:17 a:0.325164, d:-1, e:0.452470\n",
      "weak learner error rate: 0.452470\n",
      "adaboost error rate: 0.003000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:3 a:-0.547095, d:1, e:0.451373\n",
      "weak learner error rate: 0.451373\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.095000\n",
      "\n",
      "new decision stump k:13 a:0.527240, d:1, e:0.450884\n",
      "weak learner error rate: 0.450884\n",
      "adaboost error rate: 0.002000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:11 a:0.044307, d:1, e:0.451641\n",
      "weak learner error rate: 0.451641\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:17 a:0.176029, d:1, e:0.456886\n",
      "weak learner error rate: 0.456886\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:10 a:-0.706152, d:-1, e:0.449555\n",
      "weak learner error rate: 0.449555\n",
      "adaboost error rate: 0.003000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:12 a:1.130676, d:-1, e:0.442851\n",
      "weak learner error rate: 0.442851\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.095000\n",
      "\n",
      "new decision stump k:23 a:0.638320, d:1, e:0.456859\n",
      "weak learner error rate: 0.456859\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.092000\n",
      "\n",
      "new decision stump k:4 a:-0.574586, d:-1, e:0.448319\n",
      "weak learner error rate: 0.448319\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.095000\n",
      "\n",
      "new decision stump k:24 a:0.009742, d:-1, e:0.448257\n",
      "weak learner error rate: 0.448257\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:5 a:-0.163185, d:-1, e:0.448642\n",
      "weak learner error rate: 0.448642\n",
      "adaboost error rate: 0.003000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:7 a:1.509448, d:-1, e:0.449480\n",
      "weak learner error rate: 0.449480\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:0 a:0.230025, d:1, e:0.448882\n",
      "weak learner error rate: 0.448882\n",
      "adaboost error rate: 0.002000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:22 a:-1.688130, d:-1, e:0.444523\n",
      "weak learner error rate: 0.444523\n",
      "adaboost error rate: 0.002000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:22 a:1.556315, d:-1, e:0.431018\n",
      "weak learner error rate: 0.431018\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:9 a:0.854521, d:1, e:0.458870\n",
      "weak learner error rate: 0.458870\n",
      "adaboost error rate: 0.002000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:21 a:0.089346, d:-1, e:0.450543\n",
      "weak learner error rate: 0.450543\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:4 a:0.463984, d:-1, e:0.452688\n",
      "weak learner error rate: 0.452688\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.094000\n",
      "\n",
      "new decision stump k:20 a:-0.359751, d:1, e:0.459218\n",
      "weak learner error rate: 0.459218\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.090000\n",
      "\n",
      "new decision stump k:18 a:1.084607, d:1, e:0.457940\n",
      "weak learner error rate: 0.457940\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.095000\n",
      "\n",
      "new decision stump k:12 a:0.278169, d:-1, e:0.450567\n",
      "weak learner error rate: 0.450567\n",
      "adaboost error rate: 0.002000\n",
      "test error rate: 0.094000\n",
      "\n",
      "new decision stump k:15 a:-0.557926, d:-1, e:0.440192\n",
      "weak learner error rate: 0.440192\n",
      "adaboost error rate: 0.002000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:14 a:0.576214, d:-1, e:0.449132\n",
      "weak learner error rate: 0.449132\n",
      "adaboost error rate: 0.002000\n",
      "test error rate: 0.094000\n",
      "\n",
      "new decision stump k:22 a:-0.815403, d:-1, e:0.445635\n",
      "weak learner error rate: 0.445635\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:5 a:1.326342, d:-1, e:0.442896\n",
      "weak learner error rate: 0.442896\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.093000\n",
      "\n",
      "new decision stump k:3 a:0.397359, d:1, e:0.447792\n",
      "weak learner error rate: 0.447792\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:12 a:-1.268308, d:-1, e:0.445818\n",
      "weak learner error rate: 0.445818\n",
      "adaboost error rate: 0.002000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:24 a:1.501048, d:-1, e:0.436373\n",
      "weak learner error rate: 0.436373\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:23 a:-1.060782, d:1, e:0.461215\n",
      "weak learner error rate: 0.461215\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:11 a:1.953282, d:1, e:0.446535\n",
      "weak learner error rate: 0.446535\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:15 a:0.347501, d:-1, e:0.454216\n",
      "weak learner error rate: 0.454216\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:5 a:-1.002064, d:-1, e:0.451449\n",
      "weak learner error rate: 0.451449\n",
      "adaboost error rate: 0.002000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:12 a:1.130676, d:-1, e:0.437384\n",
      "weak learner error rate: 0.437384\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:0 a:0.934825, d:1, e:0.459917\n",
      "weak learner error rate: 0.459917\n",
      "adaboost error rate: 0.002000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:17 a:0.325164, d:-1, e:0.455528\n",
      "weak learner error rate: 0.455528\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:0 a:-1.443335, d:1, e:0.454417\n",
      "weak learner error rate: 0.454417\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:6 a:1.546798, d:1, e:0.438084\n",
      "weak learner error rate: 0.438084\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:6 a:0.235406, d:-1, e:0.451437\n",
      "weak learner error rate: 0.451437\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:20 a:-1.278869, d:1, e:0.454065\n",
      "weak learner error rate: 0.454065\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:3 a:2.155925, d:1, e:0.444944\n",
      "weak learner error rate: 0.444944\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:10 a:0.747340, d:-1, e:0.455351\n",
      "weak learner error rate: 0.455351\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:17 a:0.176029, d:1, e:0.454867\n",
      "weak learner error rate: 0.454867\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:24 a:-0.658157, d:-1, e:0.454185\n",
      "weak learner error rate: 0.454185\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:22 a:1.556315, d:-1, e:0.449642\n",
      "weak learner error rate: 0.449642\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:11 a:0.972829, d:1, e:0.459614\n",
      "weak learner error rate: 0.459614\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:22 a:-0.604107, d:-1, e:0.456917\n",
      "weak learner error rate: 0.456917\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:19 a:0.631011, d:-1, e:0.451421\n",
      "weak learner error rate: 0.451421\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.097000\n",
      "\n",
      "new decision stump k:4 a:-1.056969, d:-1, e:0.451331\n",
      "weak learner error rate: 0.451331\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:12 a:1.190079, d:-1, e:0.441100\n",
      "weak learner error rate: 0.441100\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.097000\n",
      "\n",
      "new decision stump k:20 a:0.554391, d:1, e:0.454614\n",
      "weak learner error rate: 0.454614\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:12 a:-0.987326, d:-1, e:0.452338\n",
      "weak learner error rate: 0.452338\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:4 a:1.603861, d:-1, e:0.438839\n",
      "weak learner error rate: 0.438839\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.093000\n",
      "\n",
      "new decision stump k:0 a:-0.522132, d:1, e:0.453861\n",
      "weak learner error rate: 0.453861\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.092000\n",
      "\n",
      "new decision stump k:3 a:1.571166, d:1, e:0.445708\n",
      "weak learner error rate: 0.445708\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.094000\n",
      "\n",
      "new decision stump k:21 a:1.198854, d:-1, e:0.459241\n",
      "weak learner error rate: 0.459241\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.094000\n",
      "\n",
      "new decision stump k:3 a:-0.580466, d:1, e:0.458407\n",
      "weak learner error rate: 0.458407\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.093000\n",
      "\n",
      "new decision stump k:13 a:1.287796, d:1, e:0.443650\n",
      "weak learner error rate: 0.443650\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:2 a:-0.181224, d:-1, e:0.456315\n",
      "weak learner error rate: 0.456315\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:4 a:0.284898, d:-1, e:0.455467\n",
      "weak learner error rate: 0.455467\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:12 a:-0.402147, d:-1, e:0.454403\n",
      "weak learner error rate: 0.454403\n",
      "adaboost error rate: 0.001000\n",
      "test error rate: 0.100000\n",
      "\n",
      "new decision stump k:5 a:0.313816, d:-1, e:0.453569\n",
      "weak learner error rate: 0.453569\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:21 a:-0.329009, d:-1, e:0.447256\n",
      "weak learner error rate: 0.447256\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:22 a:0.100921, d:-1, e:0.449560\n",
      "weak learner error rate: 0.449560\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:15 a:-0.950660, d:-1, e:0.456995\n",
      "weak learner error rate: 0.456995\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:15 a:1.189373, d:-1, e:0.442901\n",
      "weak learner error rate: 0.442901\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.097000\n",
      "\n",
      "new decision stump k:23 a:-1.060782, d:1, e:0.455309\n",
      "weak learner error rate: 0.455309\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.095000\n",
      "\n",
      "new decision stump k:20 a:1.043791, d:1, e:0.445144\n",
      "weak learner error rate: 0.445144\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.095000\n",
      "\n",
      "new decision stump k:16 a:-0.694090, d:-1, e:0.455551\n",
      "weak learner error rate: 0.455551\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.097000\n",
      "\n",
      "new decision stump k:12 a:1.190079, d:-1, e:0.450785\n",
      "weak learner error rate: 0.450785\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.095000\n",
      "\n",
      "new decision stump k:3 a:0.110023, d:1, e:0.447283\n",
      "weak learner error rate: 0.447283\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:0 a:0.377479, d:1, e:0.449712\n",
      "weak learner error rate: 0.449712\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:9 a:-0.483446, d:-1, e:0.456605\n",
      "weak learner error rate: 0.456605\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:5 a:1.326342, d:-1, e:0.458304\n",
      "weak learner error rate: 0.458304\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.093000\n",
      "\n",
      "new decision stump k:9 a:-0.048100, d:1, e:0.449004\n",
      "weak learner error rate: 0.449004\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:18 a:0.481482, d:1, e:0.459395\n",
      "weak learner error rate: 0.459395\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:9 a:-0.275164, d:-1, e:0.444565\n",
      "weak learner error rate: 0.444565\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:5 a:-0.939140, d:-1, e:0.456874\n",
      "weak learner error rate: 0.456874\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.106000\n",
      "\n",
      "new decision stump k:22 a:1.647596, d:-1, e:0.445661\n",
      "weak learner error rate: 0.445661\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.096000\n",
      "\n",
      "new decision stump k:20 a:-0.288138, d:1, e:0.456329\n",
      "weak learner error rate: 0.456329\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.093000\n",
      "\n",
      "new decision stump k:18 a:1.444907, d:1, e:0.456573\n",
      "weak learner error rate: 0.456573\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.097000\n",
      "\n",
      "new decision stump k:12 a:0.409962, d:-1, e:0.458070\n",
      "weak learner error rate: 0.458070\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:3 a:-1.231435, d:1, e:0.446416\n",
      "weak learner error rate: 0.446416\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.098000\n",
      "\n",
      "new decision stump k:3 a:2.155925, d:1, e:0.435145\n",
      "weak learner error rate: 0.435145\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:24 a:0.894221, d:-1, e:0.458215\n",
      "weak learner error rate: 0.458215\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:9 a:-0.048100, d:1, e:0.459698\n",
      "weak learner error rate: 0.459698\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:22 a:-1.531023, d:-1, e:0.440327\n",
      "weak learner error rate: 0.440327\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.105000\n",
      "\n",
      "new decision stump k:4 a:1.603861, d:-1, e:0.442524\n",
      "weak learner error rate: 0.442524\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.100000\n",
      "\n",
      "new decision stump k:23 a:-0.716626, d:1, e:0.461232\n",
      "weak learner error rate: 0.461232\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:11 a:2.447582, d:1, e:0.453425\n",
      "weak learner error rate: 0.453425\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.103000\n",
      "\n",
      "new decision stump k:1 a:0.462475, d:-1, e:0.459690\n",
      "weak learner error rate: 0.459690\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.100000\n",
      "\n",
      "new decision stump k:12 a:-1.375652, d:-1, e:0.446773\n",
      "weak learner error rate: 0.446773\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:15 a:1.621393, d:-1, e:0.435516\n",
      "weak learner error rate: 0.435516\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.099000\n",
      "\n",
      "new decision stump k:0 a:-0.593297, d:1, e:0.459113\n",
      "weak learner error rate: 0.459113\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.095000\n",
      "\n",
      "new decision stump k:1 a:0.644310, d:1, e:0.452646\n",
      "weak learner error rate: 0.452646\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:11 a:-0.669408, d:1, e:0.454603\n",
      "weak learner error rate: 0.454603\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.093000\n",
      "\n",
      "new decision stump k:13 a:1.114835, d:1, e:0.452587\n",
      "weak learner error rate: 0.452587\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.100000\n",
      "\n",
      "new decision stump k:4 a:-0.574586, d:-1, e:0.445218\n",
      "weak learner error rate: 0.445218\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.102000\n",
      "\n",
      "new decision stump k:1 a:0.462475, d:-1, e:0.451003\n",
      "weak learner error rate: 0.451003\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.101000\n",
      "\n",
      "new decision stump k:12 a:-0.129760, d:-1, e:0.453435\n",
      "weak learner error rate: 0.453435\n",
      "adaboost error rate: 0.000000\n",
      "test error rate: 0.099000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataFile = 'ada_data.mat'\n",
    "data = scio.loadmat(dataFile)\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train'].ravel()\n",
    "y_test = data['y_test'].ravel()\n",
    "\n",
    "### Your Code Here ###\n",
    "error_train,error_test=adaboost(X_train,y_train,X_test,y_test,300)\n",
    "### Your Code Here ###"
   ]
  },
  {
   "source": [
    "## Plot figures"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'error')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 392.14375 262.19625\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-05-21T21:47:23.611796</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 262.19625 \r\nL 392.14375 262.19625 \r\nL 392.14375 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 50.14375 224.64 \r\nL 384.94375 224.64 \r\nL 384.94375 7.2 \r\nL 50.14375 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m249cd87b61\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"65.361932\" xlink:href=\"#m249cd87b61\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(62.180682 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"116.258861\" xlink:href=\"#m249cd87b61\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(109.896361 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"167.15579\" xlink:href=\"#m249cd87b61\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(157.61204 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"218.052719\" xlink:href=\"#m249cd87b61\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 150 -->\r\n      <g transform=\"translate(208.508969 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"268.949648\" xlink:href=\"#m249cd87b61\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 200 -->\r\n      <g transform=\"translate(259.405898 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"319.846578\" xlink:href=\"#m249cd87b61\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 250 -->\r\n      <g transform=\"translate(310.302828 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"370.743507\" xlink:href=\"#m249cd87b61\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 300 -->\r\n      <g transform=\"translate(361.199757 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_8\">\r\n     <!-- iteration -->\r\n     <g transform=\"translate(196.421094 252.916562)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n       <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n       <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n       <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"66.992188\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"128.515625\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"169.628906\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"230.908203\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"270.117188\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"297.900391\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"359.082031\" xlink:href=\"#DejaVuSans-110\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m0b47f86229\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m0b47f86229\" y=\"214.756364\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.00 -->\r\n      <g transform=\"translate(20.878125 218.555582)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m0b47f86229\" y=\"190.590994\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.05 -->\r\n      <g transform=\"translate(20.878125 194.390212)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m0b47f86229\" y=\"166.425623\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.10 -->\r\n      <g transform=\"translate(20.878125 170.224842)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m0b47f86229\" y=\"142.260253\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.15 -->\r\n      <g transform=\"translate(20.878125 146.059472)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m0b47f86229\" y=\"118.094883\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.20 -->\r\n      <g transform=\"translate(20.878125 121.894102)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m0b47f86229\" y=\"93.929513\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 0.25 -->\r\n      <g transform=\"translate(20.878125 97.728732)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m0b47f86229\" y=\"69.764143\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 0.30 -->\r\n      <g transform=\"translate(20.878125 73.563362)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m0b47f86229\" y=\"45.598773\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 0.35 -->\r\n      <g transform=\"translate(20.878125 49.397992)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m0b47f86229\" y=\"21.433403\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 0.40 -->\r\n      <g transform=\"translate(20.878125 25.232622)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_18\">\r\n     <!-- error -->\r\n     <g transform=\"translate(14.798438 128.022344)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"100.886719\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"139.75\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"200.931641\" xlink:href=\"#DejaVuSans-114\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_17\">\r\n    <path clip-path=\"url(#p2bc7e34031)\" d=\"M 65.361932 30.616244 \r\nL 66.37987 28.683014 \r\nL 67.397809 61.547917 \r\nL 68.415748 63.964454 \r\nL 69.433686 78.463676 \r\nL 70.451625 96.34605 \r\nL 71.469563 103.112354 \r\nL 72.487502 102.145739 \r\nL 73.50544 113.261809 \r\nL 74.523379 114.711731 \r\nL 75.541318 113.261809 \r\nL 76.559256 122.927957 \r\nL 78.595133 128.727646 \r\nL 79.613072 132.110798 \r\nL 80.631011 128.244339 \r\nL 81.648949 136.460565 \r\nL 82.666888 135.010642 \r\nL 83.684826 138.393794 \r\nL 84.702765 145.160098 \r\nL 85.720703 142.743561 \r\nL 86.738642 148.059942 \r\nL 87.756581 152.409709 \r\nL 88.774519 155.792861 \r\nL 89.792458 155.309553 \r\nL 90.810396 162.559164 \r\nL 91.828335 162.559164 \r\nL 92.846274 163.042472 \r\nL 93.864212 160.625935 \r\nL 95.900089 161.592549 \r\nL 96.918028 165.942316 \r\nL 97.935966 164.009086 \r\nL 98.953905 166.425623 \r\nL 99.971844 164.492394 \r\nL 100.989782 164.009086 \r\nL 102.007721 165.942316 \r\nL 103.025659 169.325468 \r\nL 104.043598 167.875546 \r\nL 105.061537 172.70862 \r\nL 107.097414 169.808775 \r\nL 108.115352 172.70862 \r\nL 109.133291 171.258697 \r\nL 110.151229 176.091772 \r\nL 111.169168 172.225312 \r\nL 112.187107 175.125157 \r\nL 113.205045 172.225312 \r\nL 114.222984 176.091772 \r\nL 115.240922 177.058386 \r\nL 116.258861 178.508309 \r\nL 117.2768 178.991616 \r\nL 118.294738 181.89146 \r\nL 119.312677 183.341383 \r\nL 120.330615 185.75792 \r\nL 121.348554 183.82469 \r\nL 122.366492 187.207842 \r\nL 123.384431 183.82469 \r\nL 124.40237 183.341383 \r\nL 125.420308 183.82469 \r\nL 126.438247 185.75792 \r\nL 127.456185 186.241227 \r\nL 128.474124 190.107686 \r\nL 129.492063 190.107686 \r\nL 130.510001 188.657764 \r\nL 131.52794 185.75792 \r\nL 132.545878 191.557608 \r\nL 133.563817 188.657764 \r\nL 134.581755 188.174457 \r\nL 135.599694 191.074301 \r\nL 136.617633 192.524223 \r\nL 137.635571 189.624379 \r\nL 138.65351 190.107686 \r\nL 139.671448 192.040916 \r\nL 140.689387 190.107686 \r\nL 141.707326 192.040916 \r\nL 142.725264 193.490838 \r\nL 143.743203 190.107686 \r\nL 144.761141 193.007531 \r\nL 145.77908 193.007531 \r\nL 146.797018 191.557608 \r\nL 147.814957 191.557608 \r\nL 148.832896 197.357297 \r\nL 149.850834 192.040916 \r\nL 150.868773 195.907375 \r\nL 151.886711 194.94076 \r\nL 152.90465 197.357297 \r\nL 153.922589 194.457453 \r\nL 154.940527 197.357297 \r\nL 155.958466 198.807219 \r\nL 156.976404 197.357297 \r\nL 157.994343 199.290527 \r\nL 159.012281 197.357297 \r\nL 160.03022 198.323912 \r\nL 161.048159 196.87399 \r\nL 162.066097 196.390682 \r\nL 163.084036 197.357297 \r\nL 164.101974 197.840605 \r\nL 165.119913 195.907375 \r\nL 166.137852 196.390682 \r\nL 167.15579 199.290527 \r\nL 168.173729 198.807219 \r\nL 169.191667 199.773834 \r\nL 171.227544 199.773834 \r\nL 172.245483 200.740449 \r\nL 173.263422 201.223756 \r\nL 174.28136 200.740449 \r\nL 175.299299 199.773834 \r\nL 176.317237 201.223756 \r\nL 177.335176 201.223756 \r\nL 178.353115 202.673679 \r\nL 179.371053 200.257142 \r\nL 180.388992 201.223756 \r\nL 181.40693 201.223756 \r\nL 182.424869 202.673679 \r\nL 183.442807 200.257142 \r\nL 184.460746 203.640293 \r\nL 185.478685 202.190371 \r\nL 186.496623 204.123601 \r\nL 187.514562 203.156986 \r\nL 188.5325 205.090216 \r\nL 189.550439 205.090216 \r\nL 190.568378 204.606908 \r\nL 191.586316 206.540138 \r\nL 192.604255 205.090216 \r\nL 193.622193 205.090216 \r\nL 194.640132 206.05683 \r\nL 197.693948 207.506753 \r\nL 198.711886 207.506753 \r\nL 199.729825 206.05683 \r\nL 200.747763 207.506753 \r\nL 201.765702 207.99006 \r\nL 202.783641 207.99006 \r\nL 203.801579 207.506753 \r\nL 204.819518 208.956675 \r\nL 205.837456 207.99006 \r\nL 208.891272 207.99006 \r\nL 209.909211 207.506753 \r\nL 210.927149 208.473367 \r\nL 211.945088 207.023445 \r\nL 212.963026 208.473367 \r\nL 213.980965 207.99006 \r\nL 214.998904 208.473367 \r\nL 216.016842 207.99006 \r\nL 217.034781 209.439982 \r\nL 218.052719 207.506753 \r\nL 219.070658 207.506753 \r\nL 220.088596 207.023445 \r\nL 221.106535 208.473367 \r\nL 222.124474 207.99006 \r\nL 223.142412 209.439982 \r\nL 224.160351 211.373212 \r\nL 225.178289 209.439982 \r\nL 226.196228 209.92329 \r\nL 227.214167 208.956675 \r\nL 228.232105 210.889904 \r\nL 229.250044 209.92329 \r\nL 230.267982 210.889904 \r\nL 231.285921 210.406597 \r\nL 232.303859 208.956675 \r\nL 233.321798 210.889904 \r\nL 234.339737 209.92329 \r\nL 235.357675 209.92329 \r\nL 236.375614 209.439982 \r\nL 238.411491 210.406597 \r\nL 239.42943 210.406597 \r\nL 240.447368 210.889904 \r\nL 241.465307 210.406597 \r\nL 242.483245 212.823134 \r\nL 243.501184 211.856519 \r\nL 244.519122 211.856519 \r\nL 245.537061 212.339827 \r\nL 246.555 211.856519 \r\nL 247.572938 211.856519 \r\nL 248.590877 212.339827 \r\nL 250.626754 211.373212 \r\nL 251.644693 211.373212 \r\nL 252.662631 212.339827 \r\nL 253.68057 210.889904 \r\nL 254.698508 212.823134 \r\nL 255.716447 211.856519 \r\nL 256.734385 212.339827 \r\nL 257.752324 213.306441 \r\nL 258.770263 213.306441 \r\nL 259.788201 212.823134 \r\nL 260.80614 211.373212 \r\nL 261.824078 213.789749 \r\nL 263.859956 212.823134 \r\nL 264.877894 213.789749 \r\nL 265.895833 212.823134 \r\nL 267.93171 213.789749 \r\nL 268.949648 213.306441 \r\nL 269.967587 213.306441 \r\nL 270.985526 214.273056 \r\nL 272.003464 213.789749 \r\nL 273.021403 214.756364 \r\nL 274.039341 214.273056 \r\nL 275.05728 213.306441 \r\nL 276.075219 214.756364 \r\nL 277.093157 214.756364 \r\nL 278.111096 214.273056 \r\nL 279.129034 214.273056 \r\nL 280.146973 213.306441 \r\nL 281.164911 214.273056 \r\nL 282.18285 213.789749 \r\nL 283.200789 213.789749 \r\nL 284.218727 214.273056 \r\nL 285.236666 213.789749 \r\nL 286.254604 214.756364 \r\nL 287.272543 214.273056 \r\nL 288.290482 214.756364 \r\nL 290.326359 213.789749 \r\nL 292.362236 213.789749 \r\nL 293.380174 214.273056 \r\nL 295.416052 214.273056 \r\nL 296.43399 213.789749 \r\nL 298.469867 214.756364 \r\nL 299.487806 214.273056 \r\nL 300.505745 214.273056 \r\nL 301.523683 213.789749 \r\nL 302.541622 214.756364 \r\nL 303.55956 213.789749 \r\nL 304.577499 214.756364 \r\nL 329.008025 214.756364 \r\nL 330.025963 214.273056 \r\nL 331.043902 214.756364 \r\nL 369.725568 214.756364 \r\nL 369.725568 214.756364 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_18\">\r\n    <path clip-path=\"url(#p2bc7e34031)\" d=\"M 65.361932 17.083636 \r\nL 66.37987 31.099551 \r\nL 67.397809 64.931069 \r\nL 68.415748 69.764143 \r\nL 69.433686 69.280836 \r\nL 71.469563 77.497062 \r\nL 72.487502 83.29675 \r\nL 73.50544 79.430291 \r\nL 74.523379 94.896128 \r\nL 75.541318 86.679902 \r\nL 76.559256 94.896128 \r\nL 79.613072 103.595661 \r\nL 80.631011 102.145739 \r\nL 81.648949 112.778502 \r\nL 82.666888 111.32858 \r\nL 83.684826 110.845272 \r\nL 84.702765 119.544806 \r\nL 85.720703 119.061498 \r\nL 86.738642 120.028113 \r\nL 87.756581 129.694261 \r\nL 88.774519 125.827802 \r\nL 89.792458 126.311109 \r\nL 90.810396 127.761031 \r\nL 91.828335 128.727646 \r\nL 92.846274 126.794417 \r\nL 93.864212 128.727646 \r\nL 94.882151 128.727646 \r\nL 95.900089 131.627491 \r\nL 96.918028 130.660876 \r\nL 97.935966 137.427179 \r\nL 98.953905 135.49395 \r\nL 99.971844 134.044028 \r\nL 100.989782 134.527335 \r\nL 102.007721 144.67679 \r\nL 103.025659 139.360409 \r\nL 104.043598 141.293639 \r\nL 105.061537 137.427179 \r\nL 106.079475 141.293639 \r\nL 107.097414 142.260253 \r\nL 108.115352 146.61002 \r\nL 109.133291 140.810331 \r\nL 110.151229 139.360409 \r\nL 111.169168 141.776946 \r\nL 112.187107 142.260253 \r\nL 113.205045 139.843716 \r\nL 114.222984 144.193483 \r\nL 115.240922 137.910487 \r\nL 116.258861 143.710176 \r\nL 117.2768 141.293639 \r\nL 118.294738 143.226868 \r\nL 119.312677 149.026557 \r\nL 120.330615 149.993172 \r\nL 121.348554 150.476479 \r\nL 122.366492 151.926401 \r\nL 123.384431 149.993172 \r\nL 124.40237 152.893016 \r\nL 125.420308 154.342938 \r\nL 126.438247 151.926401 \r\nL 127.456185 155.792861 \r\nL 128.474124 154.826246 \r\nL 129.492063 153.376324 \r\nL 130.510001 154.826246 \r\nL 131.52794 153.859631 \r\nL 132.545878 154.342938 \r\nL 133.563817 156.759475 \r\nL 134.581755 156.759475 \r\nL 135.599694 155.792861 \r\nL 136.617633 153.376324 \r\nL 137.635571 155.792861 \r\nL 138.65351 153.859631 \r\nL 139.671448 151.443094 \r\nL 140.689387 152.893016 \r\nL 141.707326 153.376324 \r\nL 142.725264 152.409709 \r\nL 143.743203 152.893016 \r\nL 144.761141 155.309553 \r\nL 145.77908 152.893016 \r\nL 146.797018 156.759475 \r\nL 147.814957 154.826246 \r\nL 148.832896 151.926401 \r\nL 149.850834 156.759475 \r\nL 150.868773 153.376324 \r\nL 151.886711 155.309553 \r\nL 152.90465 153.859631 \r\nL 153.922589 156.276168 \r\nL 154.940527 155.792861 \r\nL 155.958466 154.826246 \r\nL 156.976404 158.209398 \r\nL 157.994343 155.792861 \r\nL 159.012281 161.592549 \r\nL 161.048159 159.65932 \r\nL 162.066097 162.559164 \r\nL 163.084036 161.109242 \r\nL 164.101974 163.525779 \r\nL 165.119913 163.525779 \r\nL 166.137852 162.075857 \r\nL 167.15579 162.559164 \r\nL 168.173729 158.692705 \r\nL 169.191667 161.592549 \r\nL 170.209606 164.009086 \r\nL 171.227544 160.625935 \r\nL 172.245483 161.109242 \r\nL 173.263422 166.908931 \r\nL 174.28136 164.009086 \r\nL 175.299299 164.975701 \r\nL 176.317237 164.492394 \r\nL 177.335176 165.459009 \r\nL 178.353115 165.942316 \r\nL 179.371053 166.908931 \r\nL 180.388992 164.975701 \r\nL 181.40693 164.009086 \r\nL 182.424869 159.65932 \r\nL 183.442807 164.492394 \r\nL 184.460746 160.625935 \r\nL 185.478685 165.459009 \r\nL 186.496623 164.492394 \r\nL 187.514562 162.559164 \r\nL 188.5325 162.075857 \r\nL 189.550439 164.975701 \r\nL 190.568378 168.84216 \r\nL 191.586316 162.559164 \r\nL 192.604255 163.042472 \r\nL 193.622193 164.975701 \r\nL 194.640132 164.009086 \r\nL 195.65807 161.109242 \r\nL 197.693948 160.142627 \r\nL 198.711886 161.109242 \r\nL 199.729825 164.009086 \r\nL 200.747763 162.075857 \r\nL 201.765702 164.492394 \r\nL 202.783641 164.975701 \r\nL 203.801579 165.942316 \r\nL 204.819518 165.942316 \r\nL 205.837456 164.975701 \r\nL 207.873333 164.975701 \r\nL 208.891272 165.942316 \r\nL 209.909211 168.84216 \r\nL 210.927149 165.459009 \r\nL 211.945088 165.459009 \r\nL 212.963026 164.492394 \r\nL 213.980965 166.425623 \r\nL 214.998904 162.075857 \r\nL 216.016842 165.459009 \r\nL 217.034781 165.459009 \r\nL 218.052719 163.042472 \r\nL 219.070658 165.459009 \r\nL 220.088596 163.525779 \r\nL 221.106535 168.358853 \r\nL 222.124474 166.425623 \r\nL 224.160351 167.392238 \r\nL 225.178289 167.392238 \r\nL 226.196228 165.942316 \r\nL 227.214167 165.459009 \r\nL 228.232105 165.459009 \r\nL 229.250044 164.492394 \r\nL 230.267982 164.975701 \r\nL 231.285921 164.975701 \r\nL 232.303859 164.492394 \r\nL 233.321798 164.492394 \r\nL 234.339737 164.975701 \r\nL 235.357675 167.392238 \r\nL 236.375614 164.975701 \r\nL 237.393552 165.459009 \r\nL 239.42943 167.392238 \r\nL 240.447368 166.908931 \r\nL 241.465307 168.358853 \r\nL 242.483245 168.84216 \r\nL 243.501184 166.425623 \r\nL 244.519122 167.875546 \r\nL 245.537061 166.425623 \r\nL 246.555 167.392238 \r\nL 247.572938 165.942316 \r\nL 248.590877 167.392238 \r\nL 249.608815 165.942316 \r\nL 250.626754 164.009086 \r\nL 251.644693 163.525779 \r\nL 252.662631 164.975701 \r\nL 253.68057 165.459009 \r\nL 254.698508 166.425623 \r\nL 255.716447 165.942316 \r\nL 256.734385 165.942316 \r\nL 257.752324 164.975701 \r\nL 258.770263 167.875546 \r\nL 259.788201 168.358853 \r\nL 260.80614 166.908931 \r\nL 261.824078 167.392238 \r\nL 262.842017 168.358853 \r\nL 263.859956 165.942316 \r\nL 264.877894 170.292083 \r\nL 265.895833 166.425623 \r\nL 266.913771 168.84216 \r\nL 267.93171 168.358853 \r\nL 268.949648 169.325468 \r\nL 269.967587 164.975701 \r\nL 270.985526 168.84216 \r\nL 272.003464 164.975701 \r\nL 273.021403 167.392238 \r\nL 274.039341 165.942316 \r\nL 275.05728 168.358853 \r\nL 276.075219 168.84216 \r\nL 277.093157 170.292083 \r\nL 278.111096 168.84216 \r\nL 279.129034 168.358853 \r\nL 281.164911 168.358853 \r\nL 282.18285 167.392238 \r\nL 283.200789 166.908931 \r\nL 284.218727 166.908931 \r\nL 285.236666 167.392238 \r\nL 286.254604 167.392238 \r\nL 288.290482 171.258697 \r\nL 289.30842 168.84216 \r\nL 290.326359 169.325468 \r\nL 291.344297 166.908931 \r\nL 292.362236 169.325468 \r\nL 293.380174 166.908931 \r\nL 294.398113 169.808775 \r\nL 295.416052 167.392238 \r\nL 296.43399 167.392238 \r\nL 297.451929 168.358853 \r\nL 298.469867 168.358853 \r\nL 299.487806 166.908931 \r\nL 300.505745 168.358853 \r\nL 301.523683 167.392238 \r\nL 302.541622 168.358853 \r\nL 303.55956 167.392238 \r\nL 304.577499 166.908931 \r\nL 305.595437 167.392238 \r\nL 306.613376 164.975701 \r\nL 307.631315 165.942316 \r\nL 308.649253 168.358853 \r\nL 309.667192 165.942316 \r\nL 310.68513 166.908931 \r\nL 311.703069 166.908931 \r\nL 312.721008 165.459009 \r\nL 313.738946 167.392238 \r\nL 315.774823 167.392238 \r\nL 316.792762 167.875546 \r\nL 317.8107 166.908931 \r\nL 318.828639 167.875546 \r\nL 319.846578 168.358853 \r\nL 320.864516 164.975701 \r\nL 321.882455 169.808775 \r\nL 322.900393 170.292083 \r\nL 323.918332 169.325468 \r\nL 324.936271 169.325468 \r\nL 325.954209 169.808775 \r\nL 327.990086 166.908931 \r\nL 329.008025 168.358853 \r\nL 330.025963 166.425623 \r\nL 331.043902 168.358853 \r\nL 332.061841 165.459009 \r\nL 333.079779 167.392238 \r\nL 334.097718 167.392238 \r\nL 335.115656 167.875546 \r\nL 336.133595 168.84216 \r\nL 337.151534 168.84216 \r\nL 338.169472 167.875546 \r\nL 339.187411 168.84216 \r\nL 340.205349 167.392238 \r\nL 341.223288 167.392238 \r\nL 342.241226 165.942316 \r\nL 343.259165 169.808775 \r\nL 344.277104 166.908931 \r\nL 345.295042 166.908931 \r\nL 346.312981 165.459009 \r\nL 347.330919 163.525779 \r\nL 348.348858 168.358853 \r\nL 349.366797 169.808775 \r\nL 350.384735 167.875546 \r\nL 351.402674 167.392238 \r\nL 352.420612 167.392238 \r\nL 353.438551 165.942316 \r\nL 355.474428 165.942316 \r\nL 356.492367 164.009086 \r\nL 357.510305 166.425623 \r\nL 358.528244 165.459009 \r\nL 359.546182 164.975701 \r\nL 360.564121 166.425623 \r\nL 361.58206 165.459009 \r\nL 362.599998 166.908931 \r\nL 363.617937 168.84216 \r\nL 364.635875 165.942316 \r\nL 365.653814 169.808775 \r\nL 366.671752 166.425623 \r\nL 367.689691 165.459009 \r\nL 368.70763 165.942316 \r\nL 369.725568 166.908931 \r\nL 369.725568 166.908931 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 50.14375 224.64 \r\nL 50.14375 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 384.94375 224.64 \r\nL 384.94375 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 50.14375 224.64 \r\nL 384.94375 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 50.14375 7.2 \r\nL 384.94375 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 295.285937 44.55625 \r\nL 377.94375 44.55625 \r\nQ 379.94375 44.55625 379.94375 42.55625 \r\nL 379.94375 14.2 \r\nQ 379.94375 12.2 377.94375 12.2 \r\nL 295.285937 12.2 \r\nQ 293.285937 12.2 293.285937 14.2 \r\nL 293.285937 42.55625 \r\nQ 293.285937 44.55625 295.285937 44.55625 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_19\">\r\n     <path d=\"M 297.285937 20.298437 \r\nL 317.285937 20.298437 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_20\"/>\r\n    <g id=\"text_19\">\r\n     <!-- train error -->\r\n     <g transform=\"translate(325.285937 23.798437)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path id=\"DejaVuSans-32\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\r\n      <use x=\"232.763672\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"264.550781\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"326.074219\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"365.4375\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"404.300781\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"465.482422\" xlink:href=\"#DejaVuSans-114\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_21\">\r\n     <path d=\"M 297.285937 34.976562 \r\nL 317.285937 34.976562 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_22\"/>\r\n    <g id=\"text_20\">\r\n     <!-- test error -->\r\n     <g transform=\"translate(325.285937 38.476562)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"192.041016\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"223.828125\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"285.351562\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"324.714844\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"363.578125\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"424.759766\" xlink:href=\"#DejaVuSans-114\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p2bc7e34031\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "iters = np.arange(300)\n",
    "plt.plot(iters,error_train,label='train error')\n",
    "plt.plot(iters,error_test,label='test error')\n",
    "plt.legend()\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('error')\n",
    "# plt.savefig('../doc/figures/error.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ]
}